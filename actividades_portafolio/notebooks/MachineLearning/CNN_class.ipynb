{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad final: Clasificación de imágenes satelitales con CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "inputFile = open('../data/raw/biomas.obj', 'rb')\n",
    "data = pickle.load(inputFile)\n",
    "\n",
    "processed_images = data['Images']\n",
    "labels = data['Labels']\n",
    "\n",
    "# Plot one image\n",
    "plt.imshow(processed_images[200], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 48, 48, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preparation for CNN\n",
    "x = np.array(processed_images)\n",
    "x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n",
    "x = x/255\n",
    "\n",
    "y = np.array(labels, dtype = int)\n",
    "yc = to_categorical(y)\n",
    "\n",
    "input_shape = (x.shape[1], x.shape[2], 1)\n",
    "\n",
    "num_classes = yc.shape[1]\n",
    "\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\palmi\\.conda\\envs\\concentracion\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, yc, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.1827 - loss: 1.9059 - val_accuracy: 0.3193 - val_loss: 1.7087\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3200 - loss: 1.6366 - val_accuracy: 0.5198 - val_loss: 1.3050\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3772 - loss: 1.4215 - val_accuracy: 0.5099 - val_loss: 1.2467\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.4352 - loss: 1.3317 - val_accuracy: 0.5718 - val_loss: 1.1654\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.4778 - loss: 1.2528 - val_accuracy: 0.5619 - val_loss: 1.1147\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.5282 - loss: 1.1760 - val_accuracy: 0.6460 - val_loss: 1.0305\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5647 - loss: 1.1275 - val_accuracy: 0.6337 - val_loss: 0.9919\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5691 - loss: 1.0668 - val_accuracy: 0.6312 - val_loss: 0.9869\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.6113 - loss: 1.0244 - val_accuracy: 0.6510 - val_loss: 0.9527\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6334 - loss: 0.9943 - val_accuracy: 0.6485 - val_loss: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x239761fb9a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74        68\n",
      "           1       0.65      0.88      0.75        68\n",
      "           2       0.53      0.51      0.52        61\n",
      "           3       0.61      0.43      0.51        76\n",
      "           4       0.73      0.88      0.80        68\n",
      "           5       0.51      0.52      0.52        63\n",
      "\n",
      "    accuracy                           0.65       404\n",
      "   macro avg       0.65      0.65      0.64       404\n",
      "weighted avg       0.65      0.65      0.64       404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
    "print(classification_report(np.argmax(y_test, axis=-1), y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\palmi\\.conda\\envs\\concentracion\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.1743 - loss: 1.8413 - val_accuracy: 0.1658 - val_loss: 1.7224\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.2013 - loss: 1.7031 - val_accuracy: 0.3837 - val_loss: 1.5388\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.3293 - loss: 1.5207 - val_accuracy: 0.4653 - val_loss: 1.2928\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.4046 - loss: 1.3818 - val_accuracy: 0.5173 - val_loss: 1.2217\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.4375 - loss: 1.3039 - val_accuracy: 0.5297 - val_loss: 1.1267\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.4972 - loss: 1.2297 - val_accuracy: 0.5520 - val_loss: 1.0510\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5342 - loss: 1.1525 - val_accuracy: 0.5916 - val_loss: 1.0062\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.5803 - loss: 1.1185 - val_accuracy: 0.5891 - val_loss: 0.9916\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5696 - loss: 1.1032 - val_accuracy: 0.6089 - val_loss: 0.9822\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.6222 - loss: 1.0280 - val_accuracy: 0.6139 - val_loss: 0.9505\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5930 - loss: 1.0556 - val_accuracy: 0.6163 - val_loss: 0.9509\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.6412 - loss: 0.9516 - val_accuracy: 0.6386 - val_loss: 0.8620\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.6652 - loss: 0.8826 - val_accuracy: 0.6634 - val_loss: 0.8435\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6551 - loss: 0.8996 - val_accuracy: 0.6287 - val_loss: 0.8758\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6535 - loss: 0.9146 - val_accuracy: 0.5965 - val_loss: 1.0311\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6366 - loss: 0.9321 - val_accuracy: 0.6139 - val_loss: 0.8999\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6780 - loss: 0.8327 - val_accuracy: 0.6312 - val_loss: 0.8523\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.7074 - loss: 0.8019 - val_accuracy: 0.6535 - val_loss: 0.7956\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.7203 - loss: 0.7617 - val_accuracy: 0.6460 - val_loss: 0.8290\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.7428 - loss: 0.7044 - val_accuracy: 0.6683 - val_loss: 0.8108\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.7293 - loss: 0.6920 - val_accuracy: 0.6782 - val_loss: 0.8243\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7574 - loss: 0.6721 - val_accuracy: 0.6807 - val_loss: 0.8051\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7913 - loss: 0.6203 - val_accuracy: 0.6881 - val_loss: 0.8418\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7912 - loss: 0.5908 - val_accuracy: 0.6609 - val_loss: 0.8521\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7695 - loss: 0.6094 - val_accuracy: 0.6881 - val_loss: 0.8146\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8254 - loss: 0.5185 - val_accuracy: 0.6955 - val_loss: 0.8034\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8219 - loss: 0.5078 - val_accuracy: 0.6931 - val_loss: 0.8195\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8299 - loss: 0.4734 - val_accuracy: 0.6807 - val_loss: 0.8834\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.8404 - loss: 0.4713 - val_accuracy: 0.6807 - val_loss: 0.8620\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8694 - loss: 0.3892 - val_accuracy: 0.6733 - val_loss: 0.8757\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8891 - loss: 0.3498 - val_accuracy: 0.6931 - val_loss: 0.9511\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8743 - loss: 0.3579 - val_accuracy: 0.6906 - val_loss: 0.8832\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.9004 - loss: 0.3020 - val_accuracy: 0.6559 - val_loss: 0.9263\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8988 - loss: 0.3104 - val_accuracy: 0.6634 - val_loss: 0.9982\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9193 - loss: 0.2667 - val_accuracy: 0.6559 - val_loss: 1.0485\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9093 - loss: 0.2671 - val_accuracy: 0.6906 - val_loss: 0.9891\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9260 - loss: 0.2210 - val_accuracy: 0.6856 - val_loss: 1.0338\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9349 - loss: 0.2003 - val_accuracy: 0.7129 - val_loss: 1.0333\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9588 - loss: 0.1628 - val_accuracy: 0.6980 - val_loss: 1.0432\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9557 - loss: 0.1451 - val_accuracy: 0.6634 - val_loss: 1.1838\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9588 - loss: 0.1371 - val_accuracy: 0.6832 - val_loss: 1.1485\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9433 - loss: 0.1693 - val_accuracy: 0.6782 - val_loss: 1.2238\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9638 - loss: 0.1243 - val_accuracy: 0.6807 - val_loss: 1.1851\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.9797 - loss: 0.0893 - val_accuracy: 0.6832 - val_loss: 1.2170\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.9784 - loss: 0.0848 - val_accuracy: 0.6881 - val_loss: 1.2407\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9710 - loss: 0.0960 - val_accuracy: 0.6733 - val_loss: 1.2595\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9744 - loss: 0.0824 - val_accuracy: 0.6931 - val_loss: 1.2753\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 212ms/step - accuracy: 0.9926 - loss: 0.0522 - val_accuracy: 0.6856 - val_loss: 1.3587\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.9855 - loss: 0.0554 - val_accuracy: 0.6906 - val_loss: 1.3253\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - accuracy: 0.9837 - loss: 0.0601 - val_accuracy: 0.6733 - val_loss: 1.3834\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.66      0.73        67\n",
      "           1       0.77      0.81      0.79        67\n",
      "           2       0.56      0.76      0.65        68\n",
      "           3       0.52      0.59      0.55        66\n",
      "           4       0.85      0.78      0.81        67\n",
      "           5       0.61      0.45      0.52        69\n",
      "\n",
      "    accuracy                           0.67       404\n",
      "   macro avg       0.69      0.67      0.67       404\n",
      "weighted avg       0.69      0.67      0.67       404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\palmi\\.conda\\envs\\concentracion\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - accuracy: 0.1845 - loss: 1.7836 - val_accuracy: 0.2804 - val_loss: 1.6056\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step - accuracy: 0.3579 - loss: 1.5400 - val_accuracy: 0.4938 - val_loss: 1.3613\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - accuracy: 0.4268 - loss: 1.3477 - val_accuracy: 0.5533 - val_loss: 1.2243\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step - accuracy: 0.4693 - loss: 1.2422 - val_accuracy: 0.5682 - val_loss: 1.1574\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 0.5338 - loss: 1.1581 - val_accuracy: 0.6179 - val_loss: 1.0372\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 231ms/step - accuracy: 0.6008 - loss: 1.0503 - val_accuracy: 0.6278 - val_loss: 0.9778\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 194ms/step - accuracy: 0.5957 - loss: 1.0181 - val_accuracy: 0.6427 - val_loss: 0.9749\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.6393 - loss: 0.9228 - val_accuracy: 0.6377 - val_loss: 0.9762\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.6685 - loss: 0.8693 - val_accuracy: 0.6576 - val_loss: 0.9071\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7095 - loss: 0.7975 - val_accuracy: 0.6625 - val_loss: 0.8713\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.7110 - loss: 0.7563 - val_accuracy: 0.6650 - val_loss: 0.9018\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7118 - loss: 0.7617 - val_accuracy: 0.6377 - val_loss: 0.9229\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.7345 - loss: 0.7075 - val_accuracy: 0.6824 - val_loss: 0.8560\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.7567 - loss: 0.6455 - val_accuracy: 0.6675 - val_loss: 0.8838\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.7921 - loss: 0.6023 - val_accuracy: 0.6849 - val_loss: 0.8516\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.8139 - loss: 0.5160 - val_accuracy: 0.6849 - val_loss: 0.8691\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.8121 - loss: 0.5357 - val_accuracy: 0.6675 - val_loss: 1.0337\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8217 - loss: 0.5451 - val_accuracy: 0.6923 - val_loss: 0.8223\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.8469 - loss: 0.4426 - val_accuracy: 0.6948 - val_loss: 0.9330\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8762 - loss: 0.3712 - val_accuracy: 0.6700 - val_loss: 0.9529\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8936 - loss: 0.3217 - val_accuracy: 0.6824 - val_loss: 0.9417\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9047 - loss: 0.2732 - val_accuracy: 0.6923 - val_loss: 0.8857\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9353 - loss: 0.2556 - val_accuracy: 0.6898 - val_loss: 0.9883\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9295 - loss: 0.2296 - val_accuracy: 0.6973 - val_loss: 0.9536\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9310 - loss: 0.2174 - val_accuracy: 0.7171 - val_loss: 0.9468\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9455 - loss: 0.1852 - val_accuracy: 0.6898 - val_loss: 1.0130\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9541 - loss: 0.1461 - val_accuracy: 0.6998 - val_loss: 1.0651\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9544 - loss: 0.1420 - val_accuracy: 0.6973 - val_loss: 1.1382\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9448 - loss: 0.1659 - val_accuracy: 0.6898 - val_loss: 1.1211\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9484 - loss: 0.1612 - val_accuracy: 0.7196 - val_loss: 1.1142\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9700 - loss: 0.1145 - val_accuracy: 0.7246 - val_loss: 1.1513\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9815 - loss: 0.0850 - val_accuracy: 0.7047 - val_loss: 1.1854\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9802 - loss: 0.0812 - val_accuracy: 0.7047 - val_loss: 1.2388\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9828 - loss: 0.0706 - val_accuracy: 0.6973 - val_loss: 1.2653\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9782 - loss: 0.0732 - val_accuracy: 0.7146 - val_loss: 1.2539\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9860 - loss: 0.0506 - val_accuracy: 0.7196 - val_loss: 1.2912\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9848 - loss: 0.0547 - val_accuracy: 0.7022 - val_loss: 1.4271\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9833 - loss: 0.0607 - val_accuracy: 0.6824 - val_loss: 1.3863\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9821 - loss: 0.0615 - val_accuracy: 0.6923 - val_loss: 1.3326\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9897 - loss: 0.0456 - val_accuracy: 0.7047 - val_loss: 1.3048\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9916 - loss: 0.0436 - val_accuracy: 0.7072 - val_loss: 1.3789\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9939 - loss: 0.0370 - val_accuracy: 0.7196 - val_loss: 1.3928\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9963 - loss: 0.0257 - val_accuracy: 0.7196 - val_loss: 1.3936\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9944 - loss: 0.0280 - val_accuracy: 0.7146 - val_loss: 1.4722\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9953 - loss: 0.0277 - val_accuracy: 0.6948 - val_loss: 1.5296\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9957 - loss: 0.0196 - val_accuracy: 0.7122 - val_loss: 1.5086\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9936 - loss: 0.0223 - val_accuracy: 0.7122 - val_loss: 1.5539\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9984 - loss: 0.0149 - val_accuracy: 0.7097 - val_loss: 1.5973\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9973 - loss: 0.0185 - val_accuracy: 0.7122 - val_loss: 1.6790\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9917 - loss: 0.0274 - val_accuracy: 0.7171 - val_loss: 1.5692\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81        67\n",
      "           1       0.80      0.76      0.78        67\n",
      "           2       0.72      0.43      0.54        67\n",
      "           3       0.57      0.72      0.64        67\n",
      "           4       0.70      0.93      0.80        67\n",
      "           5       0.72      0.69      0.71        68\n",
      "\n",
      "    accuracy                           0.72       403\n",
      "   macro avg       0.73      0.72      0.71       403\n",
      "weighted avg       0.73      0.72      0.71       403\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\palmi\\.conda\\envs\\concentracion\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.1662 - loss: 1.8066 - val_accuracy: 0.3077 - val_loss: 1.6661\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.3089 - loss: 1.6313 - val_accuracy: 0.3896 - val_loss: 1.3865\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.3689 - loss: 1.4635 - val_accuracy: 0.5261 - val_loss: 1.2490\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.4535 - loss: 1.3172 - val_accuracy: 0.5236 - val_loss: 1.2034\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.4634 - loss: 1.2800 - val_accuracy: 0.5136 - val_loss: 1.1672\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5107 - loss: 1.2243 - val_accuracy: 0.5533 - val_loss: 1.0839\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.5221 - loss: 1.1437 - val_accuracy: 0.5558 - val_loss: 1.0359\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5508 - loss: 1.1088 - val_accuracy: 0.5906 - val_loss: 1.0116\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.5773 - loss: 1.0798 - val_accuracy: 0.5856 - val_loss: 1.0245\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6011 - loss: 1.0549 - val_accuracy: 0.6427 - val_loss: 0.9783\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6409 - loss: 0.9814 - val_accuracy: 0.5881 - val_loss: 0.9533\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6378 - loss: 0.9416 - val_accuracy: 0.6079 - val_loss: 0.9003\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.6771 - loss: 0.8545 - val_accuracy: 0.6104 - val_loss: 0.9343\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6811 - loss: 0.8333 - val_accuracy: 0.6328 - val_loss: 0.9135\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.7024 - loss: 0.8197 - val_accuracy: 0.6352 - val_loss: 0.8919\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7425 - loss: 0.7378 - val_accuracy: 0.6228 - val_loss: 0.9352\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7270 - loss: 0.7438 - val_accuracy: 0.6203 - val_loss: 0.8666\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.7680 - loss: 0.6516 - val_accuracy: 0.6303 - val_loss: 0.8756\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7828 - loss: 0.5854 - val_accuracy: 0.6700 - val_loss: 0.9202\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.7897 - loss: 0.5870 - val_accuracy: 0.6303 - val_loss: 0.8881\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8139 - loss: 0.5098 - val_accuracy: 0.6749 - val_loss: 0.8567\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8488 - loss: 0.4385 - val_accuracy: 0.6576 - val_loss: 0.9042\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8821 - loss: 0.3662 - val_accuracy: 0.6526 - val_loss: 0.9606\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8765 - loss: 0.3566 - val_accuracy: 0.6824 - val_loss: 0.9430\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8915 - loss: 0.3231 - val_accuracy: 0.6501 - val_loss: 1.0249\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9014 - loss: 0.3094 - val_accuracy: 0.6452 - val_loss: 0.9884\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9198 - loss: 0.2591 - val_accuracy: 0.6799 - val_loss: 1.0304\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9259 - loss: 0.2491 - val_accuracy: 0.6650 - val_loss: 1.1130\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9536 - loss: 0.1862 - val_accuracy: 0.6625 - val_loss: 1.2022\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9486 - loss: 0.1735 - val_accuracy: 0.6452 - val_loss: 1.1502\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9455 - loss: 0.1782 - val_accuracy: 0.6675 - val_loss: 1.4567\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9476 - loss: 0.1757 - val_accuracy: 0.6576 - val_loss: 1.2278\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.9758 - loss: 0.1219 - val_accuracy: 0.6303 - val_loss: 1.2805\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9678 - loss: 0.1093 - val_accuracy: 0.6501 - val_loss: 1.3729\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9629 - loss: 0.1307 - val_accuracy: 0.6452 - val_loss: 1.3493\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9722 - loss: 0.1050 - val_accuracy: 0.6600 - val_loss: 1.4849\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9710 - loss: 0.1100 - val_accuracy: 0.6551 - val_loss: 1.3632\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9749 - loss: 0.0856 - val_accuracy: 0.6427 - val_loss: 1.4908\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9814 - loss: 0.0686 - val_accuracy: 0.6501 - val_loss: 1.5310\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9734 - loss: 0.0738 - val_accuracy: 0.6203 - val_loss: 1.5141\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9899 - loss: 0.0534 - val_accuracy: 0.6650 - val_loss: 1.5112\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9880 - loss: 0.0458 - val_accuracy: 0.6600 - val_loss: 1.6949\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9914 - loss: 0.0375 - val_accuracy: 0.6551 - val_loss: 1.6519\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9951 - loss: 0.0319 - val_accuracy: 0.6576 - val_loss: 1.7012\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9945 - loss: 0.0309 - val_accuracy: 0.6650 - val_loss: 1.7245\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9912 - loss: 0.0333 - val_accuracy: 0.6749 - val_loss: 1.6916\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9960 - loss: 0.0313 - val_accuracy: 0.6700 - val_loss: 1.7514\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9925 - loss: 0.0335 - val_accuracy: 0.6725 - val_loss: 1.7475\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9912 - loss: 0.0383 - val_accuracy: 0.6452 - val_loss: 1.8594\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9960 - loss: 0.0215 - val_accuracy: 0.6873 - val_loss: 1.7437\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.78        67\n",
      "           1       0.70      0.66      0.68        67\n",
      "           2       0.68      0.58      0.63        67\n",
      "           3       0.62      0.61      0.62        67\n",
      "           4       0.77      0.84      0.80        67\n",
      "           5       0.58      0.66      0.62        68\n",
      "\n",
      "    accuracy                           0.69       403\n",
      "   macro avg       0.69      0.69      0.69       403\n",
      "weighted avg       0.69      0.69      0.69       403\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\palmi\\.conda\\envs\\concentracion\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.1800 - loss: 1.8962 - val_accuracy: 0.2928 - val_loss: 1.7396\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.2791 - loss: 1.6949 - val_accuracy: 0.4020 - val_loss: 1.4056\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.3615 - loss: 1.4719 - val_accuracy: 0.4665 - val_loss: 1.2978\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.3772 - loss: 1.4098 - val_accuracy: 0.5261 - val_loss: 1.2060\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.4942 - loss: 1.2472 - val_accuracy: 0.5360 - val_loss: 1.1194\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5085 - loss: 1.1904 - val_accuracy: 0.5583 - val_loss: 1.0984\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5153 - loss: 1.1741 - val_accuracy: 0.6278 - val_loss: 1.0204\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5928 - loss: 1.0645 - val_accuracy: 0.6377 - val_loss: 0.9959\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6325 - loss: 0.9933 - val_accuracy: 0.6551 - val_loss: 0.9148\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.6313 - loss: 0.9907 - val_accuracy: 0.6452 - val_loss: 0.8847\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.6683 - loss: 0.8833 - val_accuracy: 0.6501 - val_loss: 0.9382\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.6636 - loss: 0.9345 - val_accuracy: 0.6600 - val_loss: 0.8874\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6840 - loss: 0.8370 - val_accuracy: 0.6675 - val_loss: 0.8660\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.7145 - loss: 0.8013 - val_accuracy: 0.6377 - val_loss: 0.9754\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7140 - loss: 0.7863 - val_accuracy: 0.6625 - val_loss: 0.9071\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.7318 - loss: 0.7305 - val_accuracy: 0.6873 - val_loss: 0.8454\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.7452 - loss: 0.7131 - val_accuracy: 0.6303 - val_loss: 0.9837\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7459 - loss: 0.6638 - val_accuracy: 0.6849 - val_loss: 0.8211\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7914 - loss: 0.5742 - val_accuracy: 0.6799 - val_loss: 0.8443\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8240 - loss: 0.5110 - val_accuracy: 0.6551 - val_loss: 0.8448\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8493 - loss: 0.4818 - val_accuracy: 0.6973 - val_loss: 0.8390\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8587 - loss: 0.4270 - val_accuracy: 0.6600 - val_loss: 0.9060\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8608 - loss: 0.4200 - val_accuracy: 0.6799 - val_loss: 0.9095\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8608 - loss: 0.3906 - val_accuracy: 0.6526 - val_loss: 0.9642\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.8935 - loss: 0.3357 - val_accuracy: 0.6923 - val_loss: 0.9401\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9024 - loss: 0.2994 - val_accuracy: 0.6675 - val_loss: 0.9982\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9261 - loss: 0.2532 - val_accuracy: 0.6948 - val_loss: 0.9964\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9192 - loss: 0.2488 - val_accuracy: 0.6774 - val_loss: 1.0448\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9134 - loss: 0.2603 - val_accuracy: 0.6774 - val_loss: 0.9924\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9225 - loss: 0.2425 - val_accuracy: 0.6774 - val_loss: 1.0805\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9536 - loss: 0.1653 - val_accuracy: 0.6849 - val_loss: 1.1879\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9383 - loss: 0.1753 - val_accuracy: 0.6948 - val_loss: 1.1123\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9574 - loss: 0.1374 - val_accuracy: 0.6799 - val_loss: 1.1849\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9715 - loss: 0.1105 - val_accuracy: 0.6849 - val_loss: 1.2091\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9688 - loss: 0.1065 - val_accuracy: 0.6799 - val_loss: 1.2454\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9725 - loss: 0.0988 - val_accuracy: 0.7022 - val_loss: 1.1672\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9830 - loss: 0.0713 - val_accuracy: 0.6898 - val_loss: 1.2445\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9824 - loss: 0.0641 - val_accuracy: 0.7072 - val_loss: 1.3086\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9868 - loss: 0.0619 - val_accuracy: 0.6849 - val_loss: 1.3915\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9787 - loss: 0.0681 - val_accuracy: 0.6700 - val_loss: 1.5393\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9801 - loss: 0.0677 - val_accuracy: 0.6774 - val_loss: 1.4618\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9835 - loss: 0.0563 - val_accuracy: 0.6873 - val_loss: 1.3993\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9907 - loss: 0.0496 - val_accuracy: 0.6725 - val_loss: 1.4653\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9877 - loss: 0.0436 - val_accuracy: 0.6948 - val_loss: 1.4888\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9916 - loss: 0.0373 - val_accuracy: 0.6725 - val_loss: 1.5211\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9791 - loss: 0.0582 - val_accuracy: 0.6973 - val_loss: 1.4694\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9969 - loss: 0.0231 - val_accuracy: 0.6973 - val_loss: 1.4888\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9962 - loss: 0.0260 - val_accuracy: 0.6873 - val_loss: 1.5183\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9987 - loss: 0.0194 - val_accuracy: 0.6725 - val_loss: 1.6292\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9850 - loss: 0.0388 - val_accuracy: 0.6948 - val_loss: 1.5360\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.67      0.74        67\n",
      "           1       0.70      0.81      0.75        67\n",
      "           2       0.59      0.72      0.65        67\n",
      "           3       0.57      0.48      0.52        67\n",
      "           4       0.87      0.87      0.87        67\n",
      "           5       0.63      0.63      0.63        68\n",
      "\n",
      "    accuracy                           0.69       403\n",
      "   macro avg       0.70      0.69      0.69       403\n",
      "weighted avg       0.70      0.69      0.69       403\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\palmi\\.conda\\envs\\concentracion\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.1962 - loss: 1.7945 - val_accuracy: 0.3077 - val_loss: 1.5698\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.3773 - loss: 1.4853 - val_accuracy: 0.3722 - val_loss: 1.3654\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.4123 - loss: 1.3537 - val_accuracy: 0.4268 - val_loss: 1.3140\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.4338 - loss: 1.3012 - val_accuracy: 0.5285 - val_loss: 1.1967\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.5198 - loss: 1.1564 - val_accuracy: 0.5633 - val_loss: 1.1202\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.5606 - loss: 1.0827 - val_accuracy: 0.5931 - val_loss: 1.0710\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.5818 - loss: 1.0460 - val_accuracy: 0.5955 - val_loss: 1.0621\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6287 - loss: 0.9621 - val_accuracy: 0.5856 - val_loss: 1.0965\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6337 - loss: 0.9539 - val_accuracy: 0.6079 - val_loss: 1.0333\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.6725 - loss: 0.8983 - val_accuracy: 0.6402 - val_loss: 0.9804\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.7027 - loss: 0.7809 - val_accuracy: 0.6328 - val_loss: 0.9827\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7162 - loss: 0.7721 - val_accuracy: 0.6203 - val_loss: 0.9512\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.7523 - loss: 0.7251 - val_accuracy: 0.5931 - val_loss: 1.0670\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.7651 - loss: 0.6949 - val_accuracy: 0.6452 - val_loss: 0.9681\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.7669 - loss: 0.6171 - val_accuracy: 0.6600 - val_loss: 0.9612\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8037 - loss: 0.5642 - val_accuracy: 0.6452 - val_loss: 0.9531\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8149 - loss: 0.5204 - val_accuracy: 0.6501 - val_loss: 1.0122\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.8514 - loss: 0.4388 - val_accuracy: 0.6352 - val_loss: 1.0362\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.8573 - loss: 0.4089 - val_accuracy: 0.6402 - val_loss: 1.0591\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8384 - loss: 0.4315 - val_accuracy: 0.6328 - val_loss: 1.0919\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.8846 - loss: 0.3505 - val_accuracy: 0.6650 - val_loss: 1.0651\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8930 - loss: 0.3169 - val_accuracy: 0.6551 - val_loss: 1.1279\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9028 - loss: 0.2939 - val_accuracy: 0.6352 - val_loss: 1.1730\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9297 - loss: 0.2383 - val_accuracy: 0.6253 - val_loss: 1.1968\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9285 - loss: 0.2275 - val_accuracy: 0.6402 - val_loss: 1.1934\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9408 - loss: 0.1964 - val_accuracy: 0.6402 - val_loss: 1.2884\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9475 - loss: 0.1757 - val_accuracy: 0.6352 - val_loss: 1.3282\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9436 - loss: 0.1774 - val_accuracy: 0.6526 - val_loss: 1.2238\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9649 - loss: 0.1384 - val_accuracy: 0.6526 - val_loss: 1.3782\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9682 - loss: 0.1029 - val_accuracy: 0.6501 - val_loss: 1.4060\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9756 - loss: 0.0963 - val_accuracy: 0.6551 - val_loss: 1.4450\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9755 - loss: 0.1008 - val_accuracy: 0.6650 - val_loss: 1.4232\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9692 - loss: 0.1029 - val_accuracy: 0.6476 - val_loss: 1.5014\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9846 - loss: 0.0811 - val_accuracy: 0.6526 - val_loss: 1.6713\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9797 - loss: 0.0744 - val_accuracy: 0.6352 - val_loss: 1.5808\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9882 - loss: 0.0467 - val_accuracy: 0.6402 - val_loss: 1.6204\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9846 - loss: 0.0560 - val_accuracy: 0.6476 - val_loss: 1.5961\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9931 - loss: 0.0395 - val_accuracy: 0.6476 - val_loss: 1.7610\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9904 - loss: 0.0378 - val_accuracy: 0.6551 - val_loss: 1.6754\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9924 - loss: 0.0400 - val_accuracy: 0.6501 - val_loss: 1.6906\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9907 - loss: 0.0423 - val_accuracy: 0.6600 - val_loss: 1.6411\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9950 - loss: 0.0303 - val_accuracy: 0.6526 - val_loss: 1.8199\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9915 - loss: 0.0315 - val_accuracy: 0.6625 - val_loss: 1.9291\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9937 - loss: 0.0237 - val_accuracy: 0.6501 - val_loss: 1.9105\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9924 - loss: 0.0253 - val_accuracy: 0.6675 - val_loss: 1.9306\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.9895 - loss: 0.0332 - val_accuracy: 0.6675 - val_loss: 1.9102\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9916 - loss: 0.0314 - val_accuracy: 0.6700 - val_loss: 1.9807\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9968 - loss: 0.0259 - val_accuracy: 0.6352 - val_loss: 2.0745\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.9930 - loss: 0.0290 - val_accuracy: 0.6452 - val_loss: 2.0058\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9950 - loss: 0.0236 - val_accuracy: 0.6551 - val_loss: 1.9192\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76        67\n",
      "           1       0.72      0.64      0.68        67\n",
      "           2       0.57      0.70      0.63        67\n",
      "           3       0.44      0.48      0.46        67\n",
      "           4       0.86      0.86      0.86        66\n",
      "           5       0.61      0.48      0.54        69\n",
      "\n",
      "    accuracy                           0.66       403\n",
      "   macro avg       0.66      0.66      0.66       403\n",
      "weighted avg       0.66      0.66      0.65       403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEFINIMOS CROSS VALIDATION\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(processed_images):\n",
    "    x_train, x_test = processed_images[train_index], processed_images[test_index]\n",
    "    y_train, y_test = labels_categorical[train_index], labels_categorical[test_index]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    # DEFINIMOS EL MODELO\n",
    "    model.fit(x_train, y_train, epochs=80, batch_size=128, verbose=1)\n",
    "\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
    "    y_test_labels = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Exactitud del pliegue: {accuracy}\")\n",
    "    print(classification_report(y_test_labels, y_pred, target_names=[str(i) for i in range(num_classes)]))\n",
    "\n",
    "print(f\"Exactitud promedio con CV: {np.mean(fold_accuracies)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concentracion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
